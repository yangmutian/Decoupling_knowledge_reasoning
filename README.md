
# Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory


This repo provides code to decouple the contribution of knowledge and reasoning. The dataset used in this paper is in ./data/input. 


## Infer (./src/run_infer.sh)


Prompt LLMs to generate answers under fast thinking and slow thinking

STEP 1: Open `./src/run_infer.sh`


STEP 2: Specify LLMs names in `MODELS`


STEP 3: Assign GPU in `GPU_IDS` (two A800 GPU)


STEP 4: Run `./src/run_infer.sh`


## Eval (./src/run_eval.sh)


Eval the answers generated by LLMs under slow thinking

STEP 1: Open `./src/run_eval.sh`


STEP 2: Specify LLMs names in `MODELS`


STEP 3: Provide your api key of ZhipuAI in  `API_KEY` (If you want to use other LLMs for evaluation, you can rewrite the code in `./code/eval.py`)


STEP 4: Run `./src/run_eval.sh`


## Citation
```
@inproceedings{
  title={Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory},
  author={Mutian Yang and Jiandong Gao and Ji Wu},
  booktitle={The 40th Annual AAAI Conference on Artificial Intelligence},
  year={2025},
}
```
